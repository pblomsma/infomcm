str(data.train)
data.test <- read.csv("http://ricknouwen.org/movie.testing.frame",
sep=",",
colClasses=c("character","character","integer"),
header=TRUE)
write.dcf(as.character(data.test[191,]$txt))
data.train <- read.csv("http://ricknouwen.org/moviereview.training.frame", sep=",", header=TRUE)
data.train$freq[data.train$freq==0] <- 0.001
### install.packages{"tokenizers"}
library(tokenizers)
tokenize_words("mY name \n is :-) MICHAEL Caine")
#Task 2
# Build a function in R that classifies strings (text)
classifyText <- function(text, model)
{
}
trainModel <- function(traindata)
{
library(tokenizers)
install.packages("tokenizers")
priors <- data.frame(term = character(), probability = double())
for (i in seq(1, length(data.train[,1]), by=2))
{
current_term <- data.train[i,1]
frequency_0 <- data.train[i,2]
frequency_1 <- data.train[i+1,2]
probability <- (frequency_0)/(frequency_0 + frequency_1)
priors
print(paste("term ", current_term))
print(paste("Probability ", probability))
}
data.train
tokenize_words("mY name \n is :-) MICHAEL Caine")
}
View(data.test)
View(data.train)
View(data.train)
str(data.train)
data.test <- read.csv("http://ricknouwen.org/movie.testing.frame",
sep=",",
colClasses=c("character","character","integer"),
header=TRUE)
write.dcf(as.character(data.test[191,]$txt))
data.train <- read.csv("http://ricknouwen.org/moviereview.training.frame", sep=",", header=TRUE)
data.train$freq[data.train$freq==0] <- 0.001
### install.packages{"tokenizers"}
library(tokenizers)
tokenize_words("mY name \n is :-) MICHAEL Caine")
#Task 2
# Build a function in R that classifies strings (text)
classifyText <- function(text, model)
{
}
trainModel <- function(traindata)
{
library(tokenizers)
install.packages("tokenizers")
priors <- data.frame(term = character(), probability = double())
for (i in seq(1, length(data.train[,1]), by=2))
{
current_term <-  as.character(data.train[i,1])
frequency_0 <- data.train[i,2]
frequency_1 <- data.train[i+1,2]
print(current_term)
priors [nrow(priors)+1,] = list(current_term,(frequency_0)/(frequency_0 + frequency_1))
}
data.train
tokenize_words("mY name \n is :-) MICHAEL Caine")
}
View(data.test)
View(data.train)
str(data.train)
data.test <- read.csv("http://ricknouwen.org/movie.testing.frame",
sep=",",
colClasses=c("character","character","integer"),
header=TRUE)
write.dcf(as.character(data.test[191,]$txt))
data.train <- read.csv("http://ricknouwen.org/moviereview.training.frame", sep=",", header=TRUE)
data.train$freq[data.train$freq==0] <- 0.001
### install.packages{"tokenizers"}
library(tokenizers)
tokenize_words("mY name \n is :-) MICHAEL Caine")
#Task 2
# Build a function in R that classifies strings (text)
classifyText <- function(text, model)
{
}
trainModel <- function(traindata)
{
library(tokenizers)
install.packages("tokenizers")
sum_0 <- sum(data.train[ which(data.train$sentiment==0), 2] )
sum_1 <- sum(data.train[ which(data.train$sentiment==1), 2] )
for (i in 1:nrow(data.train))
{
if(i %% 2 == 0) #sentiment 0
{
data.train[i,4] <- data.train[i,2] / sum_0
}
else # sentiment 1
{
data.train[i,4] <- data.train[i,2] / sum_1
}
}
priors <- data.train[ which(data.train$sentiment==1), ]
}
View(trainModel)
str(data.train)
data.test <- read.csv("http://ricknouwen.org/movie.testing.frame",
sep=",",
colClasses=c("character","character","integer"),
header=TRUE)
write.dcf(as.character(data.test[191,]$txt))
data.train <- read.csv("http://ricknouwen.org/moviereview.training.frame", sep=",", header=TRUE)
data.train$freq[data.train$freq==0] <- 0.001
### install.packages{"tokenizers"}
library(tokenizers)
tokenize_words("mY name \n is :-) MICHAEL Caine")
#Task 2
# Build a function in R that classifies strings (text)
classifyText <- function(text, model)
{
multi <- 1
for (i in length(text$probabities)) {
multi <- multi * priors$probabilities[i]
}
if (0.5 < multi < 1){
multi <- 1
}else if (0 < multi < 0.5){
multi<- 0
} else
multi <-
}
trainModel <- function(traindata)
{
library(tokenizers)
install.packages("tokenizers")
sum_0 <- sum(data.train[ which(data.train$sentiment==0), 2] )
sum_1 <- sum(data.train[ which(data.train$sentiment==1), 2] )
for (i in 1:nrow(data.train))
{
if(i %% 2 == 0) #sentiment 0
{
data.train[i,4] <- data.train[i,2] / sum_0
}
else # sentiment 1
{
data.train[i,4] <- data.train[i,2] / sum_1
}
}
priors <- data.train[ which(data.train$sentiment==1), ]
}
function(traindata)
{
library(tokenizers)
install.packages("tokenizers")
sum_0 <- sum(data.train[ which(data.train$sentiment==0), 2] )
sum_1 <- sum(data.train[ which(data.train$sentiment==1), 2] )
for (i in 1:nrow(data.train))
{
if(i %% 2 == 0) #sentiment 0
{
data.train[i,4] <- data.train[i,2] / sum_0
}
else # sentiment 1
{
data.train[i,4] <- data.train[i,2] / sum_1
}
}
priors <- data.train[ which(data.train$sentiment==1), ]
}
str(data.train)
data.test <- read.csv("http://ricknouwen.org/movie.testing.frame",
sep=",",
colClasses=c("character","character","integer"),
header=TRUE)
write.dcf(as.character(data.test[191,]$txt))
data.train <- read.csv("http://ricknouwen.org/moviereview.training.frame", sep=",", header=TRUE)
data.train$freq[data.train$freq==0] <- 0.001
### install.packages{"tokenizers"}
library(tokenizers)
tokenize_words("mY name \n is :-) MICHAEL Caine")
#Task 2
# Build a function in R that classifies strings (text)
classifyText <- function(text, model)
{
}
trainModel <- function(traindata)
{
library(tokenizers)
install.packages("tokenizers")
sum_0 <- sum(data.train[ which(data.train$sentiment==0), 2] )
sum_1 <- sum(data.train[ which(data.train$sentiment==1), 2] )
for (i in 1:nrow(data.train))
{
if(i %% 2 == 0) #sentiment 0
{
data.train[i,4] <- data.train[i,2] / sum_0
}
else # sentiment 1
{
data.train[i,4] <- data.train[i,2] / sum_1
}
}
priors <- data.train[ which(data.train$sentiment==1), ]
}
priors <- data.train[ which(data.train$sentiment==1), ]
library(tokenizers)
install.packages("tokenizers")
sum_0 <- sum(data.train[ which(data.train$sentiment==0), 2] )
sum_1 <- sum(data.train[ which(data.train$sentiment==1), 2] )
for (i in 1:nrow(data.train))
{
if(i %% 2 == 0) #sentiment 0
{
data.train[i,4] <- data.train[i,2] / sum_0
}
else # sentiment 1
{
data.train[i,4] <- data.train[i,2] / sum_1
}
}
priors <- data.train[ which(data.train$sentiment==1), ]
View(priors)
View(priors)
classification <- 5
multi <- 1
for (i in length(priors$probabities)) {
multi <- multi * priors$probabilities[i]
}
classification <- 5
if (0.5 <= multi <= 1){
classification<- 1
}else
classification<- 0
}
print(classification)
View(priors)
View(priors)
View(priors)
View(priors)
View(priors)
View(priors)
multi <- 1
for (i in length(priors$V4)) {
multi <- multi * priors$V4[i]
}
classification <- 5
if (0.5 <= multi <= 1){
classification <- 1
}else
classification<- 0
}
print(classification)
multi <- 1
for (i in length(priors$V4)) {
multi <- multi * priors$V4[i]
}
classification <- 5
if (0.5 <= multi <= 1){
classification <- 1
}else
classification<- 0
}
print(classification)
multi <- 1
for (i in length(priors$V4)) {
multi <- multi * priors$V4[i]
}
print(multi)
classification <- 5
if (0.5 <= multi <= 1){
classification <- 1
}else
classification<- 0
}
print(classification)
multi <- 1
for (i in length(priors$V4)) {
multi <- multi * priors$V4[i]
print(multi)
}
print(multi)
classification <- 5
if (0.5 <= multi <= 1){
classification <- 1
}else
classification<- 0
}
print(classification)
clean
multi <- 1
for (i in length(priors$V4)) {
multi <- multi * priors$V4[i]
print(multi)
}
print(multi)
classification <- 5
if (0.5 <= multi <= 1){
classification <- 1
}else
classification<- 0
}
print(classification)
length(priors$V4)
i <- 1
for (i in length(priors$V4)) {
multi <- multi * priors$V4[i]
print(multi)
}
print(multi)
i <- 1
for (i in length(priors$V4)) {
multi <- multi * priors$V4[i]
print(multi)
print(i)
}
multi <- 1
i <- 1
for (i in length(priors$V4)) {
multi <- multi * priors$V4[i]
print(multi)
print(i)
i <- 1
for (i in length(priors$V4)) {
multi <- multi * priors$V4[i]
print(multi)
print(i)
}
>
multi <- 1
i <- 1
for (i in length(priors$V4)) {
multi <- multi * priors$V4[i]
print(multi)
print(i)
}
print(i)
multi <- 1
for (i in 1:length(priors$V4)) {
multi <- multi * priors$V4[i]
print(multi)
print(i)
}
print(multi)
multi <- 1
for (i in 1:length(priors$V4)) {
multi <- multi * priors$V4[i]
print(multi)
}
print(multi)
sapply(priors$V4)
multi <- sapply(priors$V4,FUN = prod)
